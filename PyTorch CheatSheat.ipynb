{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# In the name of Allah\n",
    "\n",
    "This is a basic CheatSheat for pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7699, 0.1846, 0.5524],\n",
       "        [0.4099, 0.3952, 0.3869]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(2,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=np.ones(3)\n",
    "b=torch.from_numpy(n)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "# data, grad_fn, creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "x=Variable(torch.ones(3,3),requires_grad=True)\n",
    "y=x+2\n",
    "z=y*4\n",
    "f= z.mean()\n",
    "f.backward()\n",
    "print(f.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= Variable(torch.Tensor([[1],[2],[3],[4]]))\n",
    "y= Variable(torch.Tensor([[2],[4],[6],[8]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 56.85033416748047\n",
      "50 0.00042926782043650746\n",
      "100 0.0003175735764671117\n",
      "150 0.00023530315957032144\n",
      "200 0.00017434766050428152\n",
      "250 0.00012918193533550948\n",
      "300 9.571451664669439e-05\n",
      "350 7.091800216585398e-05\n",
      "400 5.254676580079831e-05\n",
      "450 3.8932907045818865e-05\n",
      "40.07625961303711\n"
     ]
    }
   ],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(LinearRegressionModel,self).__init__()\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y_predict = self.linear(x)\n",
    "        return y_predict\n",
    "\n",
    "model= LinearRegressionModel(1,1)\n",
    "citeria = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(),0.01)\n",
    "\n",
    "for epoch in range(500):\n",
    "    y_predict = model(x)\n",
    "    loss = citeria(y_predict,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%50==0:\n",
    "        print(epoch,float(loss.item()))\n",
    "        \n",
    "test = Variable(torch.Tensor([[20]]))\n",
    "z= model.forward(test)\n",
    "print(float(z.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12.516443252563477\n",
      "500 0.5113879442214966\n",
      "1000 0.5043845772743225\n",
      "1500 0.4975719153881073\n",
      "2000 0.4909436106681824\n",
      "2500 0.4844936728477478\n",
      "3000 0.4782162308692932\n",
      "3500 0.4721056818962097\n",
      "4000 0.46615657210350037\n",
      "4500 0.46036359667778015\n",
      "0.7584621906280518\n"
     ]
    }
   ],
   "source": [
    "x= Variable(torch.Tensor([[25],[35],[45],[15]]))\n",
    "y= Variable(torch.Tensor([[0],[1],[1],[0]]))\n",
    "\n",
    "import torch.nn.functional as f\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(LogisticRegressionModel,self).__init__()\n",
    "        self.linear = nn.Linear(input_size,output_size)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y_predict = torch.sigmoid(self.linear(x))\n",
    "        return y_predict\n",
    "\n",
    "model= LogisticRegressionModel(1,1)\n",
    "citeria = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(),0.001)\n",
    "\n",
    "for epoch in range(5000):\n",
    "    y_predict = model(x)\n",
    "    loss = citeria(y_predict,y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%500==0:\n",
    "        print(epoch,float(loss.item()))\n",
    "        \n",
    "test = Variable(torch.Tensor([[40]]))\n",
    "z= model.forward(test)\n",
    "print(float(z.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
